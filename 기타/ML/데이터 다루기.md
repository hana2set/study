> 모델 구축보다 데이터 평가, 정리, 변환에 드는 비용이 더 큼  
>  -> 데이터를 다루는 것이 더 중요한 작업!

# 수치형 자료(numerical data)

> 특징 공학(feature engineering)
> - 원시 데이터를 모델이 이해하고 처리할 수 있는 유용한 피처로 변환하는 과정
>   - 정규화 : 숫자 값을 표준 범위로 변환
>   - binning (== bucketing): 숫자 값을 범위의 묶음으로 분류하는 작업

### 참고. 좋은 numerical features
- 명확한 이름
- 검증된 데이터 (이상치 제거됨)
- 합리적인 데이터 (sensible)

## 데이터 확인하기

### 데이터 시각화
- 숨겨진 이상 징후, 패턴을 찾는데 도움
- 산점도, 히스토그램 등
- pandas 이용 권장
  - 누락된 데이터 작업
  - 시각화

### 데이터 통계적 평가
- 평균과 중앙값
- 표준 편차
- 사분위수 구분값

### 이상치 찾기
- 극단적 이상치 - 삭제 (보통 실수로 발생)
- 그외 - clipping 같은 특징 공학 기술 활용

#### 클리핑
- 양측 상한, 하한을 고정시키고 그 외의 값은 무시하는 방법
- 극단적 이상치의 영향을 최소화함

## 정규화
- 모델 학습을 효과적으로 수행할 수 있도록 변환
- 장점
  - 모델이 더 빠르게 수렴함
  - 모델이 더 빠르게 적합한 가중치를 찾음
  - 더 나은 예측 가능
  - "NaN 함정" 방지 (소수점 한계 초과 등)
- 요약
  
  | 정규화 기술       | 공식                                                                 | 언제 사용할 것인가                                           |
  |------------------|----------------------------------------------------------------------|--------------------------------------------------------------|
  | 선형 스케일링     | $x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}}$                     | 해당 특성이 고정된 범위에 걸쳐 균일하게 분포되는 경우.       |
  | Z-점수 스케일링   | $x' = \frac{x - \mu}{\sigma}$                                       | 특징 분포에 극단적인 이상치가 포함되지 않은 경우.           |
  | 로그 스케일링     | $x' = \log(x + \epsilon)$                                           | 해당 특성이 거듭제곱 법칙을 따르거나, 분포가 치우쳐 있는 경우. |
  | Clipping         | $x' = \min(\max(x, a), b)$                                           | 해당 특성에 극단적인 이상치가 포함된 경우.                  |

 

### 선형 스케일링
- 표준 범위(0 ~ 1 또는 -1 ~ 1)로 변환하는 것
- 적합한 데이터
  - 상한과 하한이 변하지 않음
  - 이상치가 거의 없음. 극단적이지 않음
  - 균일하게 분포



### Z-score 스케일링
- 평균으로부터 값이 떨어져 있는 표준편차의 갯수
- 적합한 데이터
  - 정규 분포와 비슷한 분포를 따름
- 극단적인 이상치 포함 가능
  
$$ x' = \frac{x - \mu}{\sigma} $$

- $x'$: Z-점수
- $\mu$: 평균
- ${\sigma}$: 표준편차

### 로그 스케일링
- 원시값의 로그를 계산
- 적합한 데이터
  - 데이터가 멱함수 분포일때 유용
  ![다운로드](https://github.com/user-attachments/assets/27774087-8dcb-4e6a-84e5-47bcd641093f)
- 예시
  - 사용자 평점
  - 도서 구매

## 비닝 (binning, bucketing)
- 데이터를 구간형 범주 데이터(bins or buckets)로 변경함.
- 적합한 데이터
  - 전반적인 Feature과 Label 간 선형 관계가 약하거나 존재하지 않음
  - Feature가 클러스티링 되는 경우

> 심화. 분위수 비닝 (Quantile Bucketing)  
> - 편향된 데이터일 경우 활
>   ![image](https://github.com/user-attachments/assets/f540b2bb-318c-4fcc-a1a7-76841c7bbec9)



## 스크러빙
- **데이터 클렌징(data cleansing)** 또는 **데이터 정제(data cleaning)** 의 하위 개념 또는 동의어
- 부정확하거나 불완전한 데이터를 자동화된 절차 또는 수작업으로 식별, 수정, 제거하여 품질을 개선
- 다음과 같은 문제에 사용
  - 생략된 값
  - 중복된 예
  - 범위를 벗어난 기능 값


## 다항식 변환
- 이차항을 x로 표현하여 선형 회귀 문제처럼 취급할 수 있다고 함.




# 범주형 자료(categorical data)

> 용어 정리
> dimension: feature vector의 개수
> sparse feature(희소 특성): 대부분 값이 비어있거나 0인 특성
> Sparse representation(희소 표현): 희소 특성 중 0이 아닌 벡터의 위치(의 모임)
> gold labels: 사람이 직접 지정한 레이블
> silver labels: 모델로 자동으로 결정되는 기계 레이블

- 모델이 분석하려면 수치형 자료가 있어야 함.
- 따라서, **vocabulary(어휘)** 를 분석하려면 어휘를 **변환(encoding)** 해줘야함.
- 다양한 이상치는 하나의 벡터로 묶음

## 원핫 인코딩(one-hot encoding)
- 범주형 데이터를 다음과 같은 벡터로 표현
  - 한 요소가 1로 설정
  - 다른 모든 요소는 0으로 설정
  ![image](https://github.com/user-attachments/assets/524f2c8b-4ac0-4cf5-bfdd-f848911e5d9e)
- 카테고리 값이 적을 때 유용.
  - 많으면 임베딩 모듈 활용할 것 (데이터 차원을 줄이는 주요 방법)

> 참고: 멀티-핫 인코딩은 여러 값이 1이 될 수 있음

## 특성 교차 (Feature crosses)
- 모델의 표현력을 높이기 위해 **두 개 이상의 feature를 조합해 새로운 피처를 생성**하는 기법
- 선형 모델로 비선형 관계을 처리할 수 있도록 함 (수치형 - 다항식 변환, 범주형 - 특성 교차)
- **희소성 증가 주의!**


# 데이터 세트

## 데이터 특성
- 예제의 모음
- 데이터 품질 = 신뢰성
  - 레이블 오류, 노이즈, 적절한 필터링 등의 문제를 해결해야함.
  - 문제들의 원인
    - 누락된 값
    - 중복
    - 잘못된 feature, label

## 레이블
- Direct labels: 진짜 정답을 직접적으로 측정한 값
- Proxy labels: 진짜 정답을 근사(approximate)하는 값 (보통 직접 레이블을 못찾아서 사용)
- 사람이 생성한 데이터(레이블)
  - 장점
    - 광범위한 데이터
    - 생성 과정에서 소유자가 일관되고 명확한 기준을 갖게 만듬
  - 단점
    - 너무 큰 비용
    - 실수를 처리해야함
    - 평가자의 숙련
## 불균형한 데이터셋 (Imbalanced datasets)
- 레이블의 불균형을 의미
> 용어
> 다수 클래스(majority class): 불균형 데이터셋에서 상대적으로 수가 많은 클래스
> 소수 클래스(minority class): 상대적으로 적은 클래스
> 다운샘플링(Downsampling): 다수 클래스 예제 중 비례적으로 낮은 하위 집합에 대해 학습하는 것
> 업웨이팅(Upweighting): 다운샘플링된 클래스에 다운샘플링한 요소와 동일한 예시 가중치를 추가하는 것

### 불균형 데이터셋 처리법
  - 다수 클래스(majority class)의 가중치를 낮춤
    1. 다수 분류를 다운샘플링함
    2. 다운샘플링된 클래스 업웨이팅(가중치 추가)

### 재조정 비율
  - 다운샘플링, 업웨이팅 비율은 어떻게? -> 직접 실험하는 수밖에 없음.
    - 불균형 비율 (소수 클래스가 충분해야함)
    - 배치 크기 (불균형 비율보다 몇 배 커야함)
    - 훈련 세트의 예제 수 

## 데이터 세트 분할
- 훈련 세트, 검증 세트, 테스트 세트로 분할한 후 사용해야함.
  - 훈련한 세트로 검증이나 테스트를 할 수 없기 때문. (손실률이 낮아져 검토 불가능)
  - 적정한 분할 비중 같은건 없다. 직접 해보는 수 밖에..
  ![image](https://github.com/user-attachments/assets/e695a33c-e0a4-4d26-a108-bb96755f2e64)


## 일반화 (Generalization)
- 훈련 데이터에만 잘 작동하는 것이 아니라, 본 적 없는 새로운 데이터에 대해서도 잘 예측하는 능력
- 실패 원인
  - Overfitting(과적합): 훈련 데이터에 너무 잘 맞춰서, 새로운 데이터에는 잘 작동하지 않음 → Generalization 나쁨
  - Underfitting(과소적합): 모델이 데이터의 패턴을 충분히 학습하지 못함 → Generalization 도달하지 못함
    ![underfit_fit_overfit](https://github.com/user-attachments/assets/e07a80dd-ef23-4d2d-a5df-f0bf06d17e06)
- 일반화 조건
  - 각 예시가 독립적이고 동일하게 분포
  - 데이터 세트는 정상성[^stationarity]을 가져야함
  - 데이터 세트의 각 파티션이 동일하게 분포(훈련, 검증, 테스트 세트)

### 과적합
- 원인
  - 훈련 세트가 실제 데이터(검증 세트, 테스트 세트)를 표현하지 못함
  - 모델의 높은 복잡도
    - Occam's Razor[^Occam]를 지키자.
- 과적합 감지
  - 일반화 곡선을 확인
    - 손실 곡선: 손실을 반복 횟수에 따라 표시
    - 일반화 곡선: 두개의 손실 곡선을 나타내는 그래
    - 두 손실 곡선이 특정 횟수 반복 후, 서로 발산함 (서로 수렴해야 일반화가 잘 됨)
    - 과적합을 암시하는 일반화 곡선
      ![image](https://github.com/user-attachments/assets/7f6560e9-633a-4bab-948f-f39604945a68)

#### 모델의 복잡도를 줄이는 방법
- 정규화
- 손실을 감수 (복잡도와 반비례)
  
#### 정규화율 $\lambda$
- 손실과 복잡성의 조합을 최소화하기 위한 수치
  ```math
  minimize(loss + \lambda*complexity)
  ```
- 높을수록
  - 과적합 ↓
  - 정규 분포
- 낮을수록
  - 과적합 ↑
  - 평평한 분포
- 정규화율과 학습률은 반비례 관계.




[^stationarity]: stationarity, 시계열 데이터의 통계적 성질(평균, 분산, 공분산 등)이 시간에 따라 변하지 않는 성질
[^Occam]: **불필요하게 가정을 늘리지 말라!** . 머신러닝에서는 같은 성능을 내는 두 모델이 있다면, 더 **단순한 모델을 선택하라**
