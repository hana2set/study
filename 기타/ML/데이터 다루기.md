> 모델 구축보다 데이터 평가, 정리, 변환에 드는 비용이 더 큼
>  -> 데이터를 다루는 것이 더 중요한 작업!

# 수치형 자료(numerical data)

> 특징 공학(feature engineering)
> - 원시 데이터를 모델이 이해하고 처리할 수 있는 유용한 피처로 변환하는 과정
>   - 정규화 : 숫자 값을 표준 범위로 변환
>   - binning (== bucketing): 숫자 값을 범위의 묶음으로 분류하는 작업

### 참고. 좋은 numerical features
- 명확한 이름
- 검증된 데이터 (이상치 제거됨)
- 합리적인 데이터 (sensible)

## 데이터 확인하기

### 데이터 시각화
- 숨겨진 이상 징후, 패턴을 찾는데 도움
- 산점도, 히스토그램 등
- pandas 이용 권장
  - 누락된 데이터 작업
  - 시각화

### 데이터 통계적 평가
- 평균과 중앙값
- 표준 편차
- 사분위수 구분값

### 이상치 찾기
- 극단적 이상치 - 삭제 (보통 실수로 발생)
- 그외 - clipping 같은 특징 공학 기술 활용

#### 클리핑
- 양측 상한, 하한을 고정시키고 그 외의 값은 무시하는 방법
- 극단적 이상치의 영향을 최소화함

## 정규화
- 모델 학습을 효과적으로 수행할 수 있도록 변환
- 장점
  - 모델이 더 빠르게 수렴함
  - 모델이 더 빠르게 적합한 가중치를 찾음
  - 더 나은 예측 가능
  - "NaN 함정" 방지 (소수점 한계 초과 등)
- 요약
  
  | 정규화 기술       | 공식                                                                 | 언제 사용할 것인가                                           |
  |------------------|----------------------------------------------------------------------|--------------------------------------------------------------|
  | 선형 스케일링     | $x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}}$                     | 해당 특성이 고정된 범위에 걸쳐 균일하게 분포되는 경우.       |
  | Z-점수 스케일링   | $x' = \frac{x - \mu}{\sigma}$                                       | 특징 분포에 극단적인 이상치가 포함되지 않은 경우.           |
  | 로그 스케일링     | $x' = \log(x + \epsilon)$                                           | 해당 특성이 거듭제곱 법칙을 따르거나, 분포가 치우쳐 있는 경우. |
  | Clipping         | $x' = \min(\max(x, a), b)$                                           | 해당 특성에 극단적인 이상치가 포함된 경우.                  |

 

### 선형 스케일링
- 표준 범위(0 ~ 1 또는 -1 ~ 1)로 변환하는 것
- 적합한 데이터
  - 상한과 하한이 변하지 않음
  - 이상치가 거의 없음. 극단적이지 않음
  - 균일하게 분포



### Z-score 스케일링
- 평균으로부터 값이 떨어져 있는 표준편차의 갯수
- 적합한 데이터
  - 정규 분포와 비슷한 분포를 따름
- 극단적인 이상치 포함 가능
  
$$ x' = \frac{x - \mu}{\sigma} $$

- $x'$: Z-점수
- $\mu$: 평균
- ${\sigma}$: 표준편차

### 로그 스케일링
- 원시값의 로그를 계산
- 적합한 데이터
  - 데이터가 멱함수 분포일때 유용
  ![다운로드](https://github.com/user-attachments/assets/27774087-8dcb-4e6a-84e5-47bcd641093f)
- 예시
  - 사용자 평점
  - 도서 구매

## 비닝 (binning, bucketing)
- 데이터를 구간형 범주 데이터(bins or buckets)로 변경함.
- 적합한 데이터
  - 전반적인 Feature과 Label 간 선형 관계가 약하거나 존재하지 않음
  - Feature가 클러스티링 되는 경우

> 심화. 분위수 비닝 (Quantile Bucketing)  
> - 편향된 데이터일 경우 활
>   ![image](https://github.com/user-attachments/assets/f540b2bb-318c-4fcc-a1a7-76841c7bbec9)



## 스크러빙
- **데이터 클렌징(data cleansing)** 또는 **데이터 정제(data cleaning)** 의 하위 개념 또는 동의어
- 부정확하거나 불완전한 데이터를 자동화된 절차 또는 수작업으로 식별, 수정, 제거하여 품질을 개선
- 다음과 같은 문제에 사용
  - 생략된 값
  - 중복된 예
  - 범위를 벗어난 기능 값


## 다항식 변환
- 이차항을 x로 표현하여 선형 회귀 문제처럼 취급할 수 있다고 함.




# 범주형 자료(categorical data)

> 용어 정리
> dimension: feature vector의 개수
> sparse feature(희소 특성): 대부분 값이 비어있거나 0인 특성
> Sparse representation(희소 표현): 희소 특성 중 0이 아닌 벡터의 위치(의 모임)
> gold labels: 사람이 직접 지정한 레이블
> silver labels: 모델로 자동으로 결정되는 기계 레이블

- 모델이 분석하려면 수치형 자료가 있어야 함.
- 따라서, **vocabulary(어휘)** 를 분석하려면 어휘를 **변환(encoding)** 해줘야함.
- 다양한 이상치는 하나의 벡터로 묶음

## 원핫 인코딩(one-hot encoding)
- 범주형 데이터를 다음과 같은 벡터로 표현
  - 한 요소가 1로 설정
  - 다른 모든 요소는 0으로 설정
  ![image](https://github.com/user-attachments/assets/524f2c8b-4ac0-4cf5-bfdd-f848911e5d9e)
- 카테고리 값이 적을 때 유용.
  - 많으면 임베딩 모듈 활용할 것 (데이터 차원을 줄이는 주요 방법)

> 참고: 멀티-핫 인코딩은 여러 값이 1이 될 수 있음

## 

