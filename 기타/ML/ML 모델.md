# 선형 회귀
- 특성(입력)과 라벨(출력) 간의 선형 관계를 모델링하여 예측하는 통계 기법
- 데이터를 통해 최적선을 그림
  ![image](https://github.com/user-attachments/assets/22712076-18ec-4b81-abdf-f0a9bc5921ef)

## 선형 회귀식
- 단일 특성: `y' = b + w₁x₁`
- 다중 특성: `y' = b + w₁x₁ + w₂x₂ + ... + wₙxₙ`
  - `y'`: 예측값
  - `b`: 편향(bias)
  - `w₁, w₂, ..., wₙ`: 각 특성의 가중치(weights)
  - `x₁, x₂, ..., xₙ`: 입력 특성들


## 손실
- 모델의 예측이 얼마나 잘못되었는지를 나타내는 숫자 항목
   ![image](https://github.com/user-attachments/assets/531794a2-1279-4d37-915f-482d9360f9e1)

### 손실 유형

  | 손실 함수 이름 | 정의 | 수식 표현 |
  |----------------|------|-----------|
  | **L1 손실** (절댓값 손실) | 예측값과 실제값의 차이의 절댓값의 합 | Σ &#124;y - y'&#124; |
  | **MAE** (평균 절대 오차) | L1 손실의 평균 | (1/N) × Σ &#124;y - y'&#124; |
  | **L2 손실** (제곱 손실) | 예측값과 실제값의 차이의 제곱의 합 | Σ (y - y')² |
  | **MSE** (평균 제곱 오차) | L2 손실의 평균 | (1/N) × Σ (y - y')² |
  
  - `MAE`모델: 이상치에 둔감. 대부분의 포인트에 가깝다. -> 간단함, 직관적
    ![image](https://github.com/user-attachments/assets/6510cafe-c25c-45de-b4b3-0b276e19fe05)
  - `MSE`모델: 이상치에 민감. 오차가 커짐 
    ![image](https://github.com/user-attachments/assets/c9440698-3429-4969-ac88-67a67d42842f)
    

### 경사하강법
- 손실이 가장 작은 모델을 생성하는 가중치와 편향을 반복적으로 찾는 수학적 기법
    1. 현재 가중치와 편향으로 손실을 계산
    2. 손실을 줄이는 가중치와 편향을 이동할 방향을 결정
    3. 가중치와 편향 값을 손실을 줄이는 방향으로 조금씩 이동
    4. 1단계로 돌아가 모델이 더 이상 손실을 줄일 수 없을 때까지 이 과정을 반복
- 선형 모델의 손실 함수는 **항상 볼록 곡면을 생성**하기 때문에, 모델이 수렴하면 결국 가장 낮은 손실을 생성하는 값을 찾을 수 있음
  ![image](https://github.com/user-attachments/assets/7056f3ec-66c3-4c02-a2ff-62c4191920c4)
 
### 초매개변수(하이퍼파라미터)
- 사용자가 학습의 다양한 측면을 제어하는 변수
- **매개변수는 사용자가 제어하는 값이 아님. 모델이 계산하는 값**


#### 학습률 
- 모델이 수렴하는 속도에 영향을 미치는 부동 소수점 수
  - 작으면 학습 속도 느림, 크면 수렴하지 않고 진동
  - **데이터 세트마다 자체적인 이상적 학습률**이 있음


#### 배치 크기
- 갱신할 때 처리할 데이터 세트의 수 (1~N)
  - 대규모 데이터 세트를 일괄 처리하는 것(`전체 배치`)은 비효율적
  - 하나만 하는 경우 (`확률적 경사하강법, SGD`) 노이즈가 많다. (업데이트 과정에 손실이 커짐)
  - 그 절충안으로 임의의 배치 크기(1~N)를 입력 `미니 배치 확률적 경사하강법`

#### 에포크
- 모델이 학습 세트의 **모든 예시를 한 번 처리했음**을 의미
- 배치 크기에 에포크 수치가 영향 받음


# 로지스틱 회귀



----

출처:  
[Crash Course > 선형 회귀](https://developers.google.com/machine-learning/crash-course/linear-regression?hl=ko)  
[Python 예제 - Keras 라이브러리](https://developers.google.com/machine-learning/crash-course/linear-regression/programming-exercise?hl=ko)
