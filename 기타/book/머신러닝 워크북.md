<!-- 머신러닝 워크북 - 제이슨 벨슨 저 -->


> 총평 : 내용이 조금 난잡한 듯? 초보용으로는 부적합한 것 같음. 간단한 실습은 가능.  
> 초반부 기초적인 설명이 미흡해 실제 구조 파악은 어려움 (정확히는 "왜"에 대한 설명이 없음)  
> 숙련자용으로는 잘 모르겠음 (java 예제, 간단한 사용법 등)  
> 이해하려면 계속 검색해야해서 구조파악 위주로 읽음  

- ML 진로 할거면 박사 추천


1. 머신 러닝이란
1.1 머신 러닝의 역사
- 앨런 튜링
- 아서 사무엘
- 톰 미첼

--- 

- 요약: 머신 러닝은 인공 지능의 한 분야. 데이터로 학습하는 시스템을 디자인.

1.2 머신 러닝 알고리즘의 종류
- 지도 학습
	- 데이터로 작업
	- 편향-분산 딜레마에 주의
- 비지도 학습
	- 데이터에 숨겨진 패턴을 찾음


1.3 인간의 개입
- 머신 러닝만으로는 시작을 할 수 업승ㅁ.
- 인간의 수고와 개선이 필요

1.4 머신 러닝의 활용
- 소프트웨어 
	- 스팸 탐지
	- 음성 인식
- 주식 매매
- 로봇
- 의학과 헬스케어
- 광고
	- 로그 파일 분석
- 소매업과 전자 상거래
	- 베이키 클럽 사건(사생활 침해)
- 게임 분석
- 사물 인터넷


1.5 머신 러닝을 위한 프로그래밍 언어
- 파이썬
- R
- 매트랩
- 스칼라
- 클로저

1.6 이 책에서 사용한 소프트웨어
- 자바 1.6 이상
- 웨카 툴킷
- 머하웃
- 스프링XD
- 하둡

1.7 데이터 저장소
- UC 어바인 머신 러닝 저장소
- 인포침스
- 캐글

2. 머신러닝 계획하기
2.1 순환 주기
- 획득 - 데이터 수집
- 준비 - 데이터 정리 및 품질 정리
- 처리 - 기계 학습 수행
- 보고 - 결과 제시

2.2 모든 것은 질문으로 부터
2.3 데이터가 없어요
- 지역 사회에서 시작 (우리나라는 공공 데이터 포털)
- 경진대회

2.4 만능 솔루션은 없다.
2.5 프로세스 정의하기
- 계획
- 개발
- 테스팅
- 보고
- 개선
- 프로덕션

2.6 데이터 팀 구성하기
- 다음에 대한 지식이 있는 팀원이 필요
	- 수학과 통계
	- 프로그래밍
	- 그래픽 디자인
	- 전문 지식 (도메인 분야)

2.7 데이터 처리
- 내 컴퓨터 사용하기 (자신의 장비를 사용할 것)
- 컴퓨터 클라스터 (성능 개선, 트래픽 감소)
- 클라우드 기반 서비스 고려 (하드웨어 유지보수 편하게)

2.8 데이터 스토리지
- 물리 디스크 (작은 규모, 테스팅)
- 클라우드 기반 스토리지 (비용 비쌈)

2.9 사생활 데이터 보안
- 문화 규범
	- 옵트 인, 옵트 아웃 전략 제공할 것
- 세대적인 기대
	- 정보 제공에 대해 나이에 따른 견해가 존재.
- 사용자 데이터 익명성
	- 제 3자에게 공개하길 원치 않는 것은 **해시**되어야 함. (ex. 이름)
- '오싹한 선'을 넘지 마라
	- "이걸 어떻게 알았을까?"라고 느끼는 지점
	

2.10 데이터 품질과 정리
- 데이터 정리는 계획 단계에서 굉장히 중요한 작업임. 대부분의 시간 차지
- 확인할 내용
	- 입력 여부 - 사용자들은 이름을 입력하지 않으려함.
	- 타입
	- 길이
	- 범위
	- 포맷
- 브리트니 딜레마
	- 브리트니 스피어스에 대해 20여가지 이상의 비슷한 철자 검색어가 있음. (사용자는 본인이 틀렸다고 생각X)
	- 간단한 방법은 분류기로 검색어 비중 측정 -> 신뢰점수 매기기
- 국가 이름에는 어떤 것들이 있나?
	- 하나의 국가에 대한 다양한 표현 (Ireland, Republic of Ireland, Erie ...)
	- 입력 데이터를 통제하는 것이 좋음 (이름 -> 코드로 변환, 관리)
- 날짜와 시간 - 포맷과 파싱을 일관적으로

2.11 입력 데이터
- 데이터 형태
	- 원시 텍스트 (유니코드, 아스키코드, UTF-8)
	- CSV
	- JSON
	- YAML
	- XML
	- 스프레드 시트(excel, google spreadsheet, libre)
	- 데이터베이스
	- 이미지 (PNG, JPEG << 정보량 <<  TIFF, BMP)

2.12 결과 데이터
- 관심사에 따라 결정

2.13 실험을 두려워 마라


2.14 요약
- 계획은 중요함.
- 실수로 배울 것
- 데이터 정리는 중요
- 좋은 인적 네트워크를 구성할 것
- 질문을 많이할 것 


3. 의사결정 트리로 작업하기
3.1 의사결정트리의 기본
- 일련의 분류 규칙을 통해 데이터를 분류, 회귀하는 지도 학습 모델 중 하나
- 사용 예
	- 금융기관 - 옵션 가격 결정
	- 마케팅 - 고객 유형별 정의 및 구매 예측
	- 의학 - 질병 예측
	- 게임 - 동작과 얼굴을 인식하는 다중의사결정트리

	
- 장점
	- 이해가 쉬움
	- 다른사람에게 보여주기 쉬움
	- 데이터 준비가 따로 필요 없음 (포맷이 있으면 실행 모델 만들 수 있음)
	- 테스트로 유효성 검증도 쉬움
	- 트리가 모델화 될 때 각 단계를 볼 수 있음
	- pc 성능이 뛰어나지않아도 됨
	- 학습은 대용량 데이터도 잘됨


- 한계
	- 훈련용 데이터에 따라 지나칠 정도로 **복잡한 모델**을 만들 수 있음
		- 과적합 문제를 피하려면 잘 조정해야함.
	- 일부 개념이 학습하기 어려움


- 여러가지 알고리즘
	- ID3
		- 데이터 속성에 대한 엔트로피를 계산, 최소 엔트로피를 기준으로 작은 데이터 세트로 분류
		- 과적합 문제로 규모가 작은 트리에 사용. 잘 사용되지않음
	- C4.5
		- ID3의 개선판
	- CHAID - 처음에는 마케팅, 후에 의학과 정신의학 분야에서 사용
	- MARS - 숫자를 다룸

- 의사결정트리 작동 방식
	- 노드로 구성된 트리.
	- 루트에서 시작하여, 리프 노드의 분류로 데이터 분기처리.
	
- 의사결정트리 만들기 (알고리즘 종류에 따라 다름)
	- 기본 문제를 위한 모델을 확인
	- 모든 attr을 반복, 순회 
	- attr를 분리하여 정규화된 정보획득량을 얻음
	- 최고의 정보획득량을 가진 속성이 best_attr 
	- best_attr 속성에서 의사결정 노드가 분리되도록 만듬
	- best_attr에서 분리하여 얻은 하위 리스트에 해당 노드를 자식 노드로 추가.

- 예시
	- attr(신용카드 유무, 리뷰 참고, 이전 구매 경험) 분리 전, 후에 대한 엔트로피 계산 
	- 정보획득량 계산
	- 정보획득량이 큰 값(이전 구매 경험)이 best_attr -> 루트노드로 배치
	- 위 항목 반복
	
3.2 웨카의 의사결정트리
웨카 데이터 마이닝 도구 사용 -> 우선 스킵
- 웨카로 데이터 넣기
- 데이터 분석해 시각화 해줌
- WekaClassifier로 자바 코드로 만들기 (weka에서 제공)

이런식으로 간단한 미분류 데이터 분석 가능. 하지만 추세가 급격히 변함으로, 분류기를 최신으로 유지할 것들이


4. 베이지안 네트워크

> 확률론적 그래프 모델로, 불확실한 상황에서 변수들 간의 인과 관계를 모델링하는 데 사용
> 복잡성화 불확실성을 편리하게 다룰 수 있음

4.1 조종사부터 클리피까지
- 항공기 안전 연착 요인을 베이지안 네트워크로 측정
- 마이크로소프트 오피스의 길잡이(클리피)에 사용

4.4 베이즈 이론
- 민감도, 특이도
- 확률이 낮을 때  민감도, 특이도가 높아도 신뢰도가 낮을 수 있음.
- 초기값? 직접 입력.. -> 직관적인 감각이 있는 전문인력 필요

4.8 베이지안 네트워크 안내
- 베이지안 네트워크를 실행할 수 있는 라이브러리
	- 오픈마르코프
	- 네티카
	- 제이즈
	- 자바베이즈
	
	
4.9 요약
- 베이지안 네트워크는 직관적임
- 초기값을 도와줄 수 있는 전문가를 섭외하라.

5. 인공신경망
5.1 신경망이란?
- 인공 신경망 - 동물의 뇌가 가진 병렬적 구성을 모델화한 것
5.2 활용
- 고빈도 매매
- 신용 대출
- 데이터 센터 관리
- 로봇 공학
- 의료 모니터링

5.3 세부 내용
- 퍼셉트론 - 이진 분류기
	- 활성화 함수 - 뉴런의 출력값을 결정하는 함수
- 다층 퍼셉트론
- 역전파

5.4 데이터 준비
- 충분한 훈련용 데이터가 있어야 함. - 예상치 못한 사태 (차원의 저주)
- 이상치 제거 혹은 결측치로 변환

5.5 웨카를 사용한 인공 신경망

- 신경망 선택(Classify 패널) - MultilayerPerceptron
- 테스트 데이터 늘리기
	- errors per epoch를 고려하여 훈련용 데이터가 지나치게 많아지지 않도록 해야함.
	- 데이터가 각각 다르기 때문에, 시간이 걸림. 측정문제임으로 계속 시도해봐야함
	
5.6 자바에서 신경망 구현

5.7 요약
- 가장 중요한 것은 데이터 준비.
- 적정한 데이터 세트, 적정한 양, 적정한 훈련 방법 찾기

6. 연관 규칙 학습
> 데이터에서 항목 간의 흥미로운 관계나 패턴을 발견할 때 사용하는 머신러닝 기법

6.1 사용 분야
- 웹 사용 로그 마이닝
- 맥주와 기저궈

6.2 학습 과정
- X => Y
	- 진건, 후건
- 지지도 (supp(X), 전체 데이터에서 아이템의 비율)
- 신뢰도 (conf(X=>Y), 왼쪽을 찾았다는 조건 하에 오른쪽을 발견할 확률) 
- 향상도 (Lift(X=>Y), X,Y 아이템 집합이 독립적인 경유 관측되는 비율)
- 확신도 (conv(X=>Y), X가 Y없이 발생할 것으로 예상되는 기대 빈도의 비율)

- 프로세스 정의하기

6.3 알고리즘

- Apriori
- FP-Growth

6.4 장바구니 마이닝 - 예제
- 원시 데이터 다운로드
- 머하웃
- 하둡


7. 서포트 벡터 머신 (SVM)
7.1 설명
- 객체를 분류하는 중요한 기술
- 인공신경망과 비교 (둘다 최소 오차를 찾는 방법과 시그모이드 함수를 사용하기때문)

7.2 사용 분야
- 이미지 인식
- 필체 패턴 인식
- 단백질 분류 

7.3 기본 분류 원칙
- 이진 분류와 다중 클래스 분류
- 선형 분류기
	- 그룹에 속하는지 확인하려면 선형 분류기를 사용하여 정확한 분리선(초평면)을 확인해야함
	- 선형 분류기는 빠르고 쉽게 대량의 개체 집합 처리 가능 -> 단어 빈도 측정 등에 사용
	- 신뢰성
		- 초평면이 얼마나 정확히 분류하고 있는가 
		
7.4 방법
- 선형 분류
- 비선형 분류
	- 커널 함수
	- 방사 기저 함수
	
7.5 웨카 예제
- LibSVM 라이브러리
	
7.6 요약

8. 클러스터링
8.1 설명
- 유사한 성격을 가진 개체를 묶어 그룹으로 구성하는 것
- 사전 훈련용 데이터가 없는 비지도 학습


8.2 사용 분야
- 인터넷(광고)
- 비즈니스와 소매업
- 법 (범죄 예방)
- 컴퓨터 작업 

8.3 모델
- 중심 모델(k-means 알고리즘)
	- 개체 그룹을 몇 개의 클러스터로 나누는지? -> 직접 판단해야함
	- 클러스터 갯수
		- 경험에 따른 규칙 (개체를 2로 나눈 제곱근)
		- 엘보법
		- 교차 유효성법
		- 실루엣법
		
8.4 웨카 예제

9. 스프링 XD로 하는 실시간 머신 러닝
- 파이어호스: 기업에서 끊임없이 제공되는 스트리밍 데이터를 부르는 은어.
- 실시간 데이터 - 활용가능성이 높다!

9.2 스프링 XD 사용하기
- 스프링 XD 스트림
	- 스트림을 필터링 한뒤 전달
	- cat *.txt | wc | sed 's/^/(lines, words, characters) =/'
- 스트림의 주요 구성요소
	- 입력 소스, 싱크, 프로세서
	
9.3 트위터 데이터로부터 배우기
- 와일리 출판사의 웹사이트에서 예제 있다고함.
	- as.wiley.com/WileyCDA/WileyTitle/rpdoctCD-1118889061.html

9.4 스프링XD 설정
9.5 스프링XD와 트위터
9.6 프로세서 소개
9.7 실시간 감성 분석
- 코멘트 데이터 -> 감성 분석 (많이함)
- 기본적인 분석이 이루어지는 방법
	- 부정적 어휘, 긍정적 어휘에 점수
- 스프링 XD Taps

9.8 요약
- 스프링 XD는 다양한 데이터 스트림을 처리하기 좋은 플랫폼
- 실시간 시스템이 목표라면 스톰, 아파치 플럼, RabbitMQ와 같은 시스템 공부도 추천


10. 배치 처리로 하는 머신 러닝
10.2 배치 처리할 데이터의 고려 사항
- 크기와 빈도
- 데이터가 많은가
- 처리 방법

10.3 배치 처리 실전 예제
- 하둡
- 스쿱
- 피그
- 머하웃
- 클라우드 기반 맵리듀스

10.4 하둡 사용하기
10.5 맵리듀스 (프로그래밍 모듈)
10.6 해시태그 마이닝
- SpringXD
- Hadoop core
- 스쿱
- 머하웃

- 예제: 제품 추천
  - "누가 무엇을 평가하는 지"로 similarity co-occurrence 알고리즘을 이요하여 비슷한 아이템 추천


10.7 판매 데이터 마이닝
- 피그 (지속적으로 유입되는 데이터에 작업하도록 설계됨)

10.8 배치
- corntab

11 아파치 스파크
데이터 분석 클러스터 컴퓨팅 프레임워크

11.1 스파크는 하둡의 대안인가?
- 스파크의 강점
  - 맵리듀스에 의존하지 않음
  - 인메모리가 하둡보다 빠름
- 결론은 다른 서적에서 봐라

11.2 명령줄에서 작업하고 싶다면 스칼라나 파이썬 쓸 것

11.3 스칼라 단기 속성 코스

11.9 스파크 스트리밍
11.10 MLib: 머신 러닝 라이브러리
11.11 요약
- 머신러닝 라이브러리는 꾸준히 보고 프로젝트 전망을 확인하는 걸 추천

12. R로하는 프로그래밍
- 단순한 그래프, 통계에 유리한 듯


12.8 Aprirori 알고리즘

12.10 R과 하둡
데이터 크기가 커짐 -> R로 데이터와 메모리의 크기를 감당 못함 -> 하둡 발생
- RHadoop 프로젝트 (R작업의 확장)

12.11 요약
- 범용 프로그래밍 언어를 사용하고 싶다면? JRI/rJava 추천
- R은 좋지만, 대규모 처리 작업엔 조금 부족



부록. 서적 추천
1. 머신러닝
   - 데이터 마이닝: 데이터 속 숨은 의미를 찾는 머신 러닝의 이론과 응용, 이안 위튼
   - 집단지성 프로그래밍: 실전 예제로 살펴보는, 사트남 알랙
2. 통계학
	- 벌거벗은 통계학:복잡한 세상을 꿰둟는 수학적 통찰력
3. 빅데이터와 데이터 사이언스
4. 하둡
5. 시각화
6. 의사결정
   - 누가 내 생각을 움직이는가: 일상을 지배하는 교묘한 선택의 함정들
